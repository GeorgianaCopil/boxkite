{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from boxkite.monitoring.service import ModelMonitoringService\n",
    "\n",
    "import mlflow\n",
    "mlflow.sklearn.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run() as run:\n",
    "\n",
    "    bunch = load_diabetes()\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        bunch.data, bunch.target\n",
    "    )\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    print(\"Score: %.2f\" % model.score(X_test, Y_test))\n",
    "    with open(\"./model.pkl\", \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "    features = zip(*[bunch.feature_names, X_train.T])\n",
    "    # features = [(\"age\", [33, 23, 54, ...]), (\"sex\", [0, 1, 0]), ...]\n",
    "    ModelMonitoringService.export_text(\n",
    "        features=features, path=\"./histogram.prom\",\n",
    "    )\n",
    "    mlflow.log_artifact(\"./histogram.prom\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.info.run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "# Get this from MLflow UI\n",
    "logged_model = f\"s3://mlflow-artifacts/0/{run.info.run_id}/artifacts/model\"\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "# Predict on a Pandas DataFrame.\n",
    "import pandas as pd\n",
    "loaded_model.predict(pd.DataFrame(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(loaded_model._model_impl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What to do next\n",
    "\n",
    "Port https://github.com/basisai/boxkite/blob/master/examples/grafana-prometheus/app/serve_completed.py\n",
    "to a container that can speak to MLflow.\n",
    "\n",
    "Have it fetch a model by ID along with its histogram and serve it while exposing Prom metrics.\n",
    "\n",
    "Have Prom + Grafana in the cluster serve an appropriate dashboard (prom dashboard auto setup with provisioning or Grafana terraform provider)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!env |grep \"AWS\\|MLFLOW\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: consider using bodywork to simplify the k8s stuff for data scientists.\n",
    "import os\n",
    "\n",
    "version = \"e7a70df\"\n",
    "\n",
    "deployment = f\"\"\"\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: ml-deployment\n",
    "  labels:\n",
    "    app: ml-server\n",
    "spec:\n",
    "  replicas: 3\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: ml-server\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: ml-server\n",
    "      annotations:\n",
    "        prometheus.io/scrape: \"true\"\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: ml-server\n",
    "        image: quay.io/boxkite/boxkite-app:{version}\n",
    "        ports:\n",
    "        - containerPort: 5000\n",
    "        #command: [\"tail\", \"-f\", \"/dev/null\"]\n",
    "        env:\n",
    "        - name: MLFLOW_RUN_ID\n",
    "          value: {run.info.run_id}\n",
    "        - name: MLFLOW_TRACKING_URI\n",
    "          value: {os.environ['MLFLOW_TRACKING_URI']}          \n",
    "        - name: MLFLOW_S3_ENDPOINT_URL\n",
    "          value: {os.environ['MLFLOW_S3_ENDPOINT_URL']}\n",
    "        - name: AWS_ACCESS_KEY_ID\n",
    "          value: {os.environ['AWS_ACCESS_KEY_ID']}\n",
    "        - name: AWS_SECRET_ACCESS_KEY\n",
    "          value: {os.environ['AWS_SECRET_ACCESS_KEY']}\n",
    "\"\"\"\n",
    "\n",
    "service = \"\"\"\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: ml-server\n",
    "spec:\n",
    "  selector:\n",
    "    app: ml-server\n",
    "  ports:\n",
    "    - protocol: TCP\n",
    "      port: 80\n",
    "      targetPort: 5000\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open(\"deployment.yaml\", \"w\").write(deployment)\n",
    "open(\"service.yaml\", \"w\").write(service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat deployment.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl apply -f deployment.yaml\n",
    "!kubectl apply -f service.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!kubectl get services\n",
    "!kubectl get po"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl logs ml-deployment-7dcc7fd776-fcgff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl ml-server -H \"Content-Type: application/json\" \\\n",
    "-d \"[0.03, 0.05, -0.002, -0.01, 0.04, 0.01, 0.08, -0.04, 0.005, -0.1]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python docs/examples/kubeflow-mlflow/load.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
